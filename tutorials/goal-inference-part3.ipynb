{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen.jl Problem Set\n",
    "\n",
    "This notebook asks you to do some programming in Gen.jl, by filling in missing code blocks. The notebook asks you to:\n",
    "- Make a small extension to the model program to make the speed of the drone a random variable\n",
    "- Write a custom proposal to make inference in your extended model program more efficient\n",
    "- Experiment with changes to the scene and/or dataset and their effect on the inferred destinations.\n",
    "- Check the automated inferences against your common sense understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addprocs(4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere include(\"resources/goals/scene.jl\")\n",
    "@everywhere include(\"resources/goals/path_planner.jl\")\n",
    "@everywhere include(\"resources/goals/uniform_2d.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"resources/goals/rendering.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@program agent_model() begin\n",
    "    \n",
    "    # assumed scene\n",
    "    scene = Scene(0, 100, 0, 100) # the scene spans the square [0, 100] x [0, 100]\n",
    "    add!(scene, Tree(Point(30, 20))) # place a tree at x=30, y=20\n",
    "    add!(scene, Tree(Point(83, 80)))\n",
    "    add!(scene, Tree(Point(80, 40)))\n",
    "    \n",
    "    wall_height = 30.\n",
    "    walls = @e([\n",
    "        Wall(Point(20., 40.), 1, 40., 2., wall_height),\n",
    "        Wall(Point(60., 40.), 2, 40., 2., wall_height),\n",
    "        Wall(Point(60.-15., 80.), 1, 15. + 2., 2., wall_height),\n",
    "        Wall(Point(20., 80.), 1, 15., 2., wall_height),\n",
    "        Wall(Point(20., 40.), 2, 40., 2., wall_height) ], \"walls\")\n",
    "    for wall in walls\n",
    "        add!(scene, wall)\n",
    "    end\n",
    "    \n",
    "    # time points at which we observe the agent's location (every 10 time steps)\n",
    "    observation_times = @e(collect(linspace(0.0, 200.0, 20)), \"times\")\n",
    "    \n",
    "    # assumed speed of the agent\n",
    "    speed = 1.0\n",
    "    \n",
    "    # the starting location of the agent is a random point in the scene\n",
    "    start = @g(uniform_2d(0, 100, 0, 100), \"start\")\n",
    "    \n",
    "    # the destination of the agent is a random point in the scene\n",
    "    destination = @g(uniform_2d(0, 100, 0, 100), \"destination\")\n",
    "    \n",
    "    # the path of the agent from its start location to its destination\n",
    "    # uses a simple 2D holonomic path planner based on RRT (path_planner.jl)\n",
    "    (tree, rough_path, final_path) = plan_path(start, destination, scene)\n",
    "    \n",
    "    if isnull(final_path)\n",
    "        \n",
    "        # the agent could not find a path to its destination\n",
    "        # assume it stays at the start location indefinitely\n",
    "        locations = [start for _ in observation_times]\n",
    "    else\n",
    "        \n",
    "        # the agent found a path to its destination\n",
    "        # assume it moves from the start to the destinatoin along the path at constnat speed\n",
    "        # sample its location along this path for each time in observation times\n",
    "        locations = walk_path(get(final_path), speed, observation_times)\n",
    "    end\n",
    "    \n",
    "    # assume that the observed locations are noisy measurements of the true locations\n",
    "    # assume the noise is normally distributed with standard deviation 'noise'\n",
    "    noise = 1.0\n",
    "    for (i, t) in enumerate(observation_times)\n",
    "        measured_x = @g(normal(locations[i].x, noise), \"x$i\")\n",
    "        measured_y = @g(normal(locations[i].y, noise), \"y$i\")\n",
    "    end\n",
    "    \n",
    "    # record other program state for rendering\n",
    "    @e(final_path, \"final-path\")\n",
    "    @e(scene, \"scene\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "Modify the `agent_model` program above to make the speed of the drone a random variable. Show a number of traces sampled from the prior, and confirm that there is variability in the agent's speed between the simulations. You can use the starter code below to help generate the renderings. There are 2 rows and 6 columns in the tile plot. Sample 12 traces from your modified program and render them below.\n",
    "\n",
    "It might be easier to see the effect of your change to the model if you fix the start and destination using the `constrain!` function.\n",
    "\n",
    "NOTE: `Gen.gamma` conflicts with Julia's built-in `Base.gamma`; if you want to sample from a gamma distribution, use `Gen.gamma` not `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict());\n",
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i=1:12\n",
    "    trace = ProgramTrace()\n",
    "    \n",
    "    # CODE HERE\n",
    "    \n",
    "    attach(renderer, id(figure => i))\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "In this problem, you will show that you can infer the speed that the drone is moving, and use the inferred speed to predict the future location of the drone.\n",
    "\n",
    "First, create two test datasets of around 5 data points, that each have the drone moving at two different speeds. The speeds should be in the support of your model's prior distribution on the speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = [Point(10, 10)] # REPLACE ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = [Point(10, 10)] # REPLACE ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, fill in the function below to do generic importance sampling with the prior as the importance (i.e. proposal) distribution. The first argument is the number of importance samples to user internally, and the second argument is a sequence of initial observed locations of the drone.\n",
    "\n",
    "We've started by constaining the start location of the drone in each importance sample to the first datapoint. Add the other necessary constraints. Use the other notebooks as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function basic_inference(num_samples::Int, dataset::Vector)\n",
    "    scores = Vector{Float64}(num_samples)\n",
    "    traces = Vector{ProgramTrace}(num_samples)\n",
    "    for k=1:num_samples\n",
    "        trace = ProgramTrace()\n",
    "        constrain!(trace, \"start\", dataset[1])\n",
    "        \n",
    "        # CODE HERE\n",
    "        \n",
    "        (scores[k], _) = @generate!(agent_model(), trace)\n",
    "        traces[k] = trace\n",
    "    end\n",
    "    chosen = categorical_log(scores)\n",
    "    return traces[chosen]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the inference algorithm on the two datasets. For each dataset, run the inference algorithm 12 times to generate 12 independent approximate posterior samples, and show them in two separate tile plots.\n",
    "\n",
    "Each trace that is returned by the inference algorithm will contain a complete set of locations of the drone across the entire time sequence. The prefix of this sequence will match the constrained values. The rest will be a prediction of the remainder of the drone's path. Each rendering will show both the constrained and predicted locations. Use the renderings to confirm that the inference algorithm is inferring the speed correctly, and that the inferred speed is taken into account in the predictions.\n",
    "\n",
    "How many importance samples (the first argument to `basic_inference`) were necessary to get decent inferences about the speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run inference on dataset1 and show 12 samples in the output of the cell above\n",
    "\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run inference on dataset2 and show 12 samples in the output of the cell above\n",
    "\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "The `basic_inference` algorithm above guesses the speed by sampling it from the prior when generating each importance sample. For datasets where the drone is moving at roughly a constant speed, the speed should be pretty obvious from the dataset, and its not necessary to guess it from the prior. Fill in the probabilistic program `custom_proposal` below with code that makes an intelligent guess about the speed, given some prefix of observed locations of the drone. We've put a line at the end that samples from a standard normal disribution, and annotates that sample with the address \"speed\". Change the function so that \"speed\" is sampled from a distribution that depends on the dataset.\n",
    "\n",
    "Remember that the best proposal distribution is the posterior, and the posterior probably has some variability. You want your proposal to have some variability, but not too much (because otherwise the knowledge encoded in the program isn't being used). Experiment a bit with the parameters in your function and observe the effect on the quality of inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_proposal = @program (dataset::Vector) begin\n",
    "    \n",
    "    # CODE HERE\n",
    "\n",
    "    @g(normal(0, 1), \"speed\") # REPLACE ME\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have written a function `custom_inference` that uses your custom proposal in an importance sampler. You don't need to modify this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function custom_inference(num_samples::Int, dataset::Vector)\n",
    "    \n",
    "    # create a new generator that samples from a custom importance distribution by \n",
    "    # sampling the 'speed' from the custom_proposal program, and the remaining random choices\n",
    "    # from the prior, and returns the log importance weight as its score during `generate!`\n",
    "    composition = compose(agent_model, custom_proposal, Dict([\"speed\" => (\"speed\", Float64)]))\n",
    "    \n",
    "    trace = ProgramTrace()\n",
    "    constrain!(trace, \"start\", dataset[1])\n",
    "    for (i, point) in enumerate(dataset)\n",
    "        constrain!(trace, \"x$i\", point.x)\n",
    "        constrain!(trace, \"y$i\", point.y)\n",
    "    end\n",
    "    traces = Vector{ProgramTrace}(num_samples)\n",
    "    scores = Vector{Float64}(num_samples)\n",
    "    for k=1:num_samples\n",
    "        t = deepcopy(trace)\n",
    "        (scores[k], _) = @generate!(composition((), (dataset,)), t)\n",
    "        traces[k] = t\n",
    "    end\n",
    "    chosen = categorical_log(scores)\n",
    "    return traces[chosen]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render samples from `custom_inference` for the two datasets as you did above for `basic_inference`. Can you get  reasonable predictions using fewer importance samples (and therefore less computation) than you did with `basic_inference`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run inference on dataset1 and show 12 samples in the output of the cell above\n",
    "\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run inference on dataset2 and show 12 samples in the output of the cell above\n",
    "\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aside: Nested Inference\n",
    "\n",
    "Next, we introduce the concept of \"nested inference\", in which parts of a probabilistic model come with their own inference code built into them. This is a capability enabled by Gen's flexible `Generator` interface. Allowing modeling code to have built-in inference code for its internal random variables can allow for more modular inference programming. We'll demonstrate this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that what we really care about is predicting the drone's future locations, and its destination. The speed of the drone is not of direct domain interest---it is only important to model because it is relevant to inferences about the variables we do care about directly. We can try to follow good software engineering principles, and break our large monolithic `agent_model` procedure into smaller individually coherent units. Let's separate the parts of the model concerned with the motion of the drone from the parts concerned with the plan, by creating a separate `motion_model` procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please copy your modified distribution on `speed` into the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@program motion_model(start::Point, final_path::Nullable{Path}, observation_times::Vector{Float64}) begin\n",
    "    \n",
    "    speed = 1.0 # REPLACE ME\n",
    "    \n",
    "    if isnull(final_path)\n",
    "        locations = [start for _ in observation_times]\n",
    "    else\n",
    "        locations = walk_path(get(final_path), speed, observation_times)\n",
    "    end\n",
    "    noise = 1.0\n",
    "    measured = Vector{Point}(length(observation_times))\n",
    "    for (i, t) in enumerate(observation_times)\n",
    "        measured_x = @g(normal(locations[i].x, noise), \"x$i\")\n",
    "        measured_y = @g(normal(locations[i].y, noise), \"y$i\")\n",
    "        measured[i] = Point(measured_x, measured_y)\n",
    "    end\n",
    "    measured\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the new top-level model program is shorter. We add \"address aliases\" so that we can still use the addresses `\"speed\"`, `\"x$i\"` and `\"y$i\"` to refer to these random variables. If we didn't have the address aliases, the addresses would be tuples: `(\"motion\", \"speed\")`, `(\"motion\", \"x$i\")`, `(\"motion\", \"y$i\")`. In general, we can address parts of a program's execution deep within a call stack of probabilistic programs---the addresses just become long tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@program agent_model_refactored() begin\n",
    "    \n",
    "    scene = Scene(0, 100, 0, 100) # the scene spans the square [0, 100] x [0, 100]\n",
    "    add!(scene, Tree(Point(30, 20))) # place a tree at x=30, y=20\n",
    "    add!(scene, Tree(Point(83, 80)))\n",
    "    add!(scene, Tree(Point(80, 40)))\n",
    "    wall_height = 30.\n",
    "    walls = @e([\n",
    "        Wall(Point(20., 40.), 1, 40., 2., wall_height),\n",
    "        Wall(Point(60., 40.), 2, 40., 2., wall_height),\n",
    "        Wall(Point(60.-15., 80.), 1, 15. + 2., 2., wall_height),\n",
    "        Wall(Point(20., 80.), 1, 15., 2., wall_height),\n",
    "        Wall(Point(20., 40.), 2, 40., 2., wall_height) ], \"walls\")\n",
    "    for wall in walls\n",
    "        add!(scene, wall)\n",
    "    end\n",
    "\n",
    "    observation_times = @e(collect(linspace(0.0, 200.0, 20)), \"times\")\n",
    "    start = @g(uniform_2d(0, 100, 0, 100), \"start\")\n",
    "    destination = @g(uniform_2d(0, 100, 0, 100), \"destination\")\n",
    "    (tree, rough_path, final_path) = plan_path(start, destination, scene)\n",
    "    \n",
    "    @alias(\"speed\", (\"motion\", \"speed\"))\n",
    "    for i=1:length(observation_times)\n",
    "        @alias(\"x$i\", (\"motion\", \"x$i\"))\n",
    "        @alias(\"y$i\", (\"motion\", \"y$i\"))\n",
    "    end\n",
    "    measured_locations = @g(motion_model(start, final_path, observation_times), \"motion\")\n",
    "\n",
    "    # record other program state for rendering\n",
    "    @e(final_path, \"final-path\")\n",
    "    @e(scene, \"scene\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that inference still works by running on `dataset1` again. Let's copy the inference procedure and make it run `agent_model_refactored` instead of `agent_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function custom_inference_refactored(num_samples::Int, dataset::Vector)\n",
    "\n",
    "    composition = compose(agent_model_refactored, custom_proposal, Dict([\"speed\" => (\"speed\", Float64)]))\n",
    "    \n",
    "    trace = ProgramTrace()\n",
    "    constrain!(trace, \"start\", dataset[1])\n",
    "    for (i, point) in enumerate(dataset)\n",
    "        constrain!(trace, \"x$i\", point.x)\n",
    "        constrain!(trace, \"y$i\", point.y)\n",
    "    end\n",
    "    traces = Vector{ProgramTrace}(num_samples)\n",
    "    scores = Vector{Float64}(num_samples)\n",
    "    for k=1:num_samples\n",
    "        t = deepcopy(trace)\n",
    "        (scores[k], _) = @generate!(composition((), (dataset,)), t)\n",
    "        traces[k] = t\n",
    "    end\n",
    "    chosen = categorical_log(scores)\n",
    "    return traces[chosen]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run inference on dataset1 and show 12 samples in the output of the cell above\n",
    "\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have refactored our model program, but our inference program `custom_inference_refactored` still includes details about how to infer the speed. We can also achieve more modularity in the inference program using **nested inference**. Specifically, we implement a custom `Generator` type for the motion model, that will include nested inference over its internal \"speed\" random choice. \n",
    "\n",
    "Recall that a probabilistic program in Gen (as created with `@program`) is one type of `Generator`. A probabilistic program describes the forward generative process, but doesn't let the programmer define inference algorithms for that program within the program itself. The more general `Generator` interface is flexible enough to permit custom inference that is packaged together with the description of the generative process. We'll call our new `Generator` type `MotionModelGenerator`. We have to implement the `empty_trace` method, which returns an empty trace that this generator can write to, and the `generate!` method, which is the main entry-point into the generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct MotionModelGenerator <: Generator{ProgramTrace}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gen.empty_trace(g::MotionModelGenerator) = ProgramTrace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write our generator so that it can generate into traces that have a consecutive block of measurements constrained. In that case, it will sample the speed from the custom speed proposal distribution, and return the importance weight as its score. If there are no constraints on the measurements, it behaves just like a probabilistic program generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function Gen.generate!(generator::MotionModelGenerator, args::Tuple, trace::ProgramTrace)\n",
    "    start, path, times = args\n",
    "    num_points = length(times)\n",
    "    constrained = false\n",
    "    dataset = []\n",
    "    done = false\n",
    "    constrained = false\n",
    "    for i=1:num_points\n",
    "        x_constrained = haskey(trace, \"x$i\") && Gen.mode(trace, \"x$i\") == Gen.constrain\n",
    "        y_constrained = haskey(trace, \"y$i\") && Gen.mode(trace, \"y$i\") == Gen.constrain\n",
    "        if !x_constrained && !y_constrained\n",
    "            done = true\n",
    "        elseif x_constrained && y_constrained\n",
    "            constrained = true\n",
    "            if done\n",
    "                error(\"generator only supports constraints a consecutive prefix of points\")\n",
    "            end\n",
    "            push!(dataset, Point(trace[\"x$i\"], trace[\"y$i\"]))\n",
    "        else\n",
    "            error(\"x and y must both be constrained or both not constrained\")\n",
    "        end\n",
    "    end\n",
    "    if constrained\n",
    "        \n",
    "        # nested inference using the custom proposal to 'speed'\n",
    "        # generate! returns an importance weight\n",
    "        generator = compose(motion_model, custom_proposal, Dict([\"speed\" => (\"speed\", Float64)]))\n",
    "        return Gen.generate!(generator, (args, (dataset,)), trace)\n",
    "    else\n",
    "        \n",
    "        # behave like a probabilistic program\n",
    "        return Gen.generate!(motion_model, args, trace)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify the agent model again, to use our new custom `MotionModelGenerator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@program agent_model_nested_inference() begin\n",
    "    \n",
    "    scene = Scene(0, 100, 0, 100) # the scene spans the square [0, 100] x [0, 100]\n",
    "    add!(scene, Tree(Point(30, 20))) # place a tree at x=30, y=20\n",
    "    add!(scene, Tree(Point(83, 80)))\n",
    "    add!(scene, Tree(Point(80, 40)))\n",
    "    wall_height = 30.\n",
    "    walls = @e([\n",
    "        Wall(Point(20., 40.), 1, 40., 2., wall_height),\n",
    "        Wall(Point(60., 40.), 2, 40., 2., wall_height),\n",
    "        Wall(Point(60.-15., 80.), 1, 15. + 2., 2., wall_height),\n",
    "        Wall(Point(20., 80.), 1, 15., 2., wall_height),\n",
    "        Wall(Point(20., 40.), 2, 40., 2., wall_height) ], \"walls\")\n",
    "    for wall in walls\n",
    "        add!(scene, wall)\n",
    "    end\n",
    "\n",
    "    observation_times = @e(collect(linspace(0.0, 200.0, 20)), \"times\")\n",
    "    start = @g(uniform_2d(0, 100, 0, 100), \"start\")\n",
    "    destination = @g(uniform_2d(0, 100, 0, 100), \"destination\")\n",
    "    (tree, rough_path, final_path) = plan_path(start, destination, scene)\n",
    "    \n",
    "    for i=1:length(observation_times)\n",
    "        @alias(\"x$i\", (\"motion\", \"x$i\"))\n",
    "        @alias(\"y$i\", (\"motion\", \"y$i\"))\n",
    "    end\n",
    "    measured_locations = @g(MotionModelGenerator()(start, final_path, observation_times), \"motion\")\n",
    "\n",
    "    # record other program state for rendering\n",
    "    @e(final_path, \"final-path\")\n",
    "    @e(scene, \"scene\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample from the new generative program to make sure it behaves just likethe original one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i=1:12\n",
    "    trace = ProgramTrace()\n",
    "    constrain!(trace, \"start\", Point(10, 10))\n",
    "    constrain!(trace, \"destination\", Point(90, 90))\n",
    "    @generate!(agent_model_nested_inference(), trace)\n",
    "    attach(renderer, id(figure => i))\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we write an importance sampling program for use with the new `agent_model_nested_inference` model program. Crucially, this inference program is identical to our original `basic_inference` program---it doesn't contain mention of the speed, or of our custom proposal. Instead, the custom proposal is being invoked under the hood within the `MotionModelGenerator` every time we call `generate!` on the model program. The importance distribution used by `using_nested_inference` is the same as the importance distribution used in `custom_inference`, except that now the custom inference over the parameter of the motion model (the speed has been encapsulated inside the motion model itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function using_nested_inference(num_samples::Int, dataset::Vector)\n",
    "    scores = Vector{Float64}(num_samples)\n",
    "    traces = Vector{ProgramTrace}(num_samples)\n",
    "    for k=1:num_samples\n",
    "        trace = ProgramTrace()\n",
    "        constrain!(trace, \"start\", dataset[1])\n",
    "        for (i, point) in enumerate(dataset)\n",
    "            constrain!(trace, \"x$i\", point.x)\n",
    "            constrain!(trace, \"y$i\", point.y)\n",
    "        end\n",
    "        (scores[k], _) = @generate!(agent_model_nested_inference(), trace)\n",
    "        traces[k] = trace\n",
    "    end\n",
    "    chosen = categorical_log(scores)\n",
    "    return traces[chosen]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the inference algorithm still works by testing it on `dataset1` and `dataset2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run using_nested_inference on dataset1 and show 12 samples in the output of the cell above\n",
    "\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run using_nested_inference on dataset2 and show 12 samples in the output of the cell above\n",
    "\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "Recall that we can modify the scene by using `intervene!` on the \"walls\" as done in the earlier notebook, e.g.:\n",
    "\n",
    "    intervene!(trace, \"walls\", new_walls)\n",
    "\n",
    "Recall that `intervene!` is like `constrain!` in that it fixes the given address to a particular value in the execution of the program. However, interventions are not incorporated into the score returned by `generate!`. Interventions simply replace the value at an address. Unlike constraints, which can only be applied to generator invocations annotated with `@g`, interventions can be applied to generator invocations or arbitrary expressions annotated with `@e`. In this case, the \"walls\" are not generated by a generator invocation, and we are simply replacing that expression in the program with a new value. Note that the modification of the scene can also be achieved by making the scene an argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the dataset and/or scene, show that a change to the scene can result in drastic changes to the distribution on predicted paths, and approximate posterior distribution on destinations.\n",
    "\n",
    "We've written another inference program that takes a trace called `base_trace` as input. This `base_trace` can contain interventions, which will be copied into all of the importance samples used within the inference algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function inference(num_samples::Int, dataset::Vector, base_trace::ProgramTrace)\n",
    "    scores = Vector{Float64}(num_samples)\n",
    "    traces = Vector{ProgramTrace}(num_samples)\n",
    "    for k=1:num_samples\n",
    "        trace = deepcopy(base_trace)\n",
    "        constrain!(trace, \"start\", dataset[1])\n",
    "        for (i, point) in enumerate(dataset)\n",
    "            constrain!(trace, \"x$i\", point.x)\n",
    "            constrain!(trace, \"y$i\", point.y)\n",
    "        end\n",
    "        (scores[k], _) = @generate!(agent_model_nested_inference(), trace)\n",
    "        traces[k] = trace\n",
    "    end\n",
    "    chosen = categorical_log(scores)\n",
    "    return traces[chosen]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [Point(10, 10)] # REPLACE ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the `Wall` constructor has type signature:\n",
    "\n",
    "    Wall(start::Point, orientation::Int, length::Float64, thickness::Float64, height::Float64)\n",
    "\n",
    "`orientation=1` indicates a horizontal wall, and an `orientation=2` indicates a vertical wall.\n",
    "\n",
    "Note that the `height` does not matter, because the drone planner is operating in 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_trace = ProgramTrace()\n",
    "intervene!(base_trace, \"walls\", []) # REPLACE ME\n",
    "for i=1:20\n",
    "    attach(renderer, id(figure => i))\n",
    "    trace = inference(20, dataset, base_trace)\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_trace = ProgramTrace()\n",
    "intervene!(base_trace, \"walls\", []) # REPLACE ME\n",
    "for i=1:20\n",
    "    attach(renderer, id(figure => i))\n",
    "    trace = inference(20, dataset, base_trace)\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "\n",
    "Experiment! Change the model and/or dataset and/or inference programs in other ways.\n",
    "\n",
    "Some concrete suggestions:\n",
    "\n",
    "- Try making some properties of the scene into random choices. Can you infer something about the drone's beliefs about the scene from its motion? Do the automated inferences match your common sense inferences? Can you set up a scene and dataset to clearly illustrate that inference is working in your model? \n",
    "\n",
    "- Try improving the flexibility of the motion model further by making the noise a random variable. Test it on a dataset that matches the model's expectations and one that doesn't. Can you demonstrate that your model in which the noise level is inferred, is more robust to model mis-specification?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

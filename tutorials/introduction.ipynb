{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/header.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Authored by: Christina Curlette and Alexey Radul, Ph.D. of the MIT Probabilistic Computing Project (Probcomp). Prepared for: The DARPA PPAML PI meeting, July 2017.\n",
    "\n",
    "This is version 0 of probcomp-stack, the software stack developed by the [MIT Probabilistic Computing Project](http://probcomp.org/). The probcomp stack contains three probabilistic programming platforms:\n",
    "\n",
    "* The [bayeslite](https://github.com/probcomp/bayeslite) implementation of BayesDB, a platform for AI-assisted data science.  [[Documentation](http://probcomp.csail.mit.edu/bayesdb/doc/index.html)]\n",
    "* The [venturelite](http://probcomp.org/venture/) implementation of Venture, an interactive probabilistic reasoning platform that has been used for teaching probabilistic modeling and inference and for rapid prototyping in computer vision, data science, and robotics. [[Documentation](http://probcomp.csail.mit.edu/venture/release-0.5/reference/index.html)]\n",
    "* A pre-alpha version of Gen.jl, a Julia implementation of Gen, a probabilistic meta-programming platform and high-performance run-time system suitable for production engineering in probabilistic robotics. (no documentation is available at this time)\n",
    "\n",
    "Key capabilities of these platforms can be accessed via the notebooks included with this release.\n",
    "\n",
    "The notebooks in this release have successfully executed with the following hardware configuration, with acceptable performance:\n",
    "\n",
    "* 60G RAM\n",
    "* 32 CPU cores\n",
    "* 2.5 Gbyte available disk space\n",
    "\n",
    "Running with much less than this may lead to heavy load, long delays, and/or crashes. Actual application demands vary depending on the particulars of the data set, both on its size and on the data itself.\n",
    "\n",
    "We assume that you are using a workstation possessing the recommended resources via the workstation's monitor and keyboard.  Client/server configurations are possible for this software with additional setup, but methods vary by operating system.  We have not prepared documentation for client/server configurations.\n",
    "\n",
    "## 0. Jupyter notebooks\n",
    "If you've never worked with Jupyter (formerly iPython) notebooks before, you may want to briefly check out [the Jupyter website](http://jupyter.org/) to get familiar with the format. Jupyter notebooks allow you to intersperse cells of code, text, images, etc. in the same file. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a code cell. You can run it by hitting the button in the toolbar that looks like a \"play\" button. \n",
    "# You can also hit Shift + Enter to run the cell.\n",
    "\n",
    "print 'hello world'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BayesDB\n",
    "The BayesDB project aims to enable BayesDB users to query the probable implications of their data as easily as querying the data itself. Why is this important? Stakeholders in business, humanitarian work, science, and government are increasingly recognizing the importance of making statistical inferences from their data. Existing approaches to this problem require experts in statistical modeling or data scientists proficient in applied machine learning. These skills are projected to be in short supply as the importance of statistical inference is increasingly recognized across a variety of fields. Also, developers new to machine learning may be stymied by the maze that is the current machine learning toolkit. This toolkit can come up short in settings that don’t match canonical machine learning problems.\n",
    "\n",
    "BayesDB aims to address some of these issues with three core capabilities:\n",
    "First, the Bayesian query language, or BQL, supports flexible data analysis queries while abstracting away the choice of model. Second, this BQL abstraction is enabled by general purpose default models that are capable of handling arbitrary tabular data. Finally, BayesDB is extensible by supporting integration of external statistical models and domain knowledge, when it’s available.\n",
    "\n",
    "The default probabilistic model used in BayesDB is CrossCat, described below.\n",
    "\n",
    "## 2. CrossCat\n",
    "CrossCat is a domain-general, Bayesian method for analyzing high-dimensional data tables. CrossCat estimates the full joint distribution over the variables in the table from the data, via approximate inference in a hierarchical, nonparametric Bayesian model, and provides efficient samplers for every conditional distribution. CrossCat combines strengths of nonparametric mixture modeling and Bayesian network structure learning: it can model any joint distribution given enough data by positing latent variables, but also discovers independencies between the observable variables.\n",
    "\n",
    "A range of exploratory analysis and predictive modeling tasks can be addressed via CrossCat, including detecting predictive relationships between variables, finding multiple overlapping clusterings, imputing missing values, and simultaneously selecting features and classifying rows. Research on CrossCat has shown that it is suitable for analysis of real-world tables of up to 10 million cells, including hospital cost and quality measures, voting records, handwritten digits, and state-level unemployment time series.\n",
    "\n",
    "## 3. Venture\n",
    "Venture is a higher-order probabilistic programming language that aims to be sufficiently expressive, extensible, and efficient for general-purpose use. Some distinctive features include:\n",
    "- Sufficient expressiveness to handle problems and data sources from multiple fields, such as machine learning, robotics and statistics.\n",
    "- An inference programming language that supports combinations of exact and approximate inference techniques, including Metropolis-Hastings, mean field, sequential Monte Carlo, Hamiltonian Monte Carlo and gradient descent.\n",
    "- A JavaScript-like front-end syntax and a read-write textual representation of the abstract syntax dervied from Lisp\n",
    "- A flexible foreign interface that makes it straightforward to add new primitives, including higher-order probabilistic procedures, exchangeable sequences, and “likelihood free” primitives, and to equip them with custom inference schemes.\n",
    "- An interactive console that provides tools for inspection, profiling and debugging.\n",
    "\n",
    "## 4. Gen.jl\n",
    "Gen.jl is a featherweight embedded probabilistic programming language and compositional inference programming library for [Julia](https://julialang.org/). \n",
    "\n",
    "## 5. Tutorial notebooks\n",
    "The notebooks in this folder contain several tutorials on using BayesDB to analyze real-world data, as well as a two-part Gen.jl tutorial on inferring goals of autonomous agents. For those with significant statistics and/or machine learning background, we also provide notebooks illustrating Gaussian process extrapolation and hyperparameter inference as probabilistic programming synthesis.\n",
    "\n",
    "Each notebook will be provided in two forms: a Jupyter notebook for you to work through and a pre-rendered HTML or pdf file of the results for you to refer to as you go. Please note that the cells in the Jupyter notebooks should be run in order.\n",
    "\n",
    "The notebooks use extensions loaded from `jupyter_probcomp`, including cell magics that enable running Bayesian Query Language (BQL) queries, Metamodeling Language (MML) queries, and Venture code inline within Jupyter code cells. The basic usage of the magics is described below.\n",
    "\n",
    "Single-line BQL query:  \n",
    "`%bql <query>`\n",
    "\n",
    "Multi-line BQL query:  \n",
    "`%%bql`  \n",
    "`<query line 1>`  \n",
    "`<query line 2>`  \n",
    "`...`\n",
    "\n",
    "MML magics (`%mml`, `%%mml`) and Venture magics (`%venturescript`, `%%venturescript`) operate similarly. SQL magics (`%sql`, `%%sql`) are also supported. \n",
    "\n",
    "### 5.0 Documentation\n",
    "You will encounter many common uses of `jupyter_probcomp` functions, BQL, MML, and Venture in the notebooks we have provided. For more information, please refer to the documentation:\n",
    "- [jupyter_probcomp](https://github.com/probcomp/iventure/blob/master/docs/dot_commands.md)\n",
    "- [BQL and MML](https://probcomp-1.csail.mit.edu/reference/bayeslite/bql.html) \n",
    "- [Venture](http://probcomp.org/venture/edge/reference/)\n",
    "\n",
    "Gen.jl is still in early stages of development and thus does not have official documentation.\n",
    "\n",
    "\n",
    "The following sections suggest an order in which to work through the notebooks and provide a brief description of each notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Gapminder exploratory analysis tutorial\n",
    "The  [Gapminder exploratory analysis tutorial](./gapminder-exploratory.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/gapminder-exploratory.html)) contains a tutorial of exploratory data analysis in BayesDB. We cover the basics of loading data into data tables and creating populations and analysis schemas. We describe and visualize the outcomes of CrossCat, the default modeling building and discovery engine in BayesDB, as applied to the Gapminder dataset. We then compare probably dependencies detected by CrossCat to those discovered by linear methods such as Pearson correlation. The tutorial concludes by showing how to use BQL queries to search for database records which are probably predictive of another.\n",
    "\n",
    "### 5.2 Satellites predictive modeling tutorial\n",
    "The [satellites predictive modeling tutorial](./satellites-predictive.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/satellites-predictive.html)) contains a tutorial of predictive modeling and analysis in BayesDB. We cover how to simulate data from the learned CrossCat generative models, and compare the results of selecting and simulating the same data to show that CrossCat can recover both quantitative and qualitative features of the underlying data distribution. We also show how predictive probability in BayesDB can be used to detect anomalous values. \n",
    "\n",
    "### 5.3 Population assembly with BayesDB tutorial\n",
    "In the [population assembly tutorial](./population-assembly-tutorial.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/population-assembly-tutorial.html)), we demonstrate how to construct BayesDB analysis populations -- consisting of tabular, medium data with defined statistical types -- from a variety of data sources. We provide examples of population assembly from: (1) a neuroscience data source of fMRI imaging data plus a separate public database of word meanings, (2) the Gapminder international development data source, and (3) epidemiological data sources for tracking the spread of the flu including Twitter and CDC data.\n",
    "\n",
    "### 5.4 Gapminder missing data tutorial\n",
    "The [Gapminder missing data tutorial](./gapminder-missing-data.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/gapminder-missing-data.html)) shows how BayesDB can be used to find patterns of missing values in data and detect whether data are missing at random. This notebook also demonstrates how BayesDB  can be used to infer missing values and shows that the imputations generated by CrossCat are fairly well-calibrated. Both of theses analyses are conducted on a dataset from Gapminder.\n",
    "\n",
    "### 5.5 Goal inference with Gen.jl\n",
    "The [Gen.jl goal inference notebook part 1](./goal-inference-part1.ipynb) ([pdf](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/inferring-goals-1.pdf)), [part 2](goal-inference-part2.ipynb) ([pdf](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/inferring-goals-2.pdf)), and [part 3](goal-inference-part3.ipynb) use the Gen.jl probabilistic meta-programming library ([source](https://github.com/probcomp/Gen.jl), [documentation](http://probcomp.csail.mit.edu/gen/)) to write probabilistic models of an autonomous agent and inference algorithms that infer the goals of the agent based on its observed behavior. The notebooks also introduce a methodology for visualization of probabilistic program execution traces and the behavior of inference algorithms, and illustrates the methodology using D3.js.\n",
    "\n",
    "### 5.6 Gaussian process extrapolation as probabilistic programming synthesis\n",
    "The [Gaussian process extrapolation notebook](./extrapolation-with-gp.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/extrapolation-with-gp.html)) demonstrates extrapolation with probabilistic programming synthesis given real world data. The notebook shows how extrapolation results improve with increasing time spent on inference. The notebook also compares the Gaussian process posterior predictive to the posterior predictive generated with Bayesian linear regression.\n",
    "\n",
    "### 5.7 Gaussian process hyperparameter inference as probabilistic programming synthesis\n",
    "The [Gaussian process hyperparameter inference notebook](./hyperparameter-inference-with-gp.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/hyperparameter-inference-with-gp.html)) demonstrates hyperparameter inference in the probabilistic programming synthesis framework. We compare Metropolis-Hastings sampling and gradient ascent as two synthesis strategies for inference over GP hyperparameters; for this comparison we inspect how inference strategies explore the posterior landscape and how the Gaussian process posterior predictive differs for different inference strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

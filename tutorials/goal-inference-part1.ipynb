{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring the goals of autonomous agents in Gen.jl\n",
    "\n",
    "Gen.jl is a a runtime system and meta-programming library for compositional probabilistic generative models, inference algorithms, and deep learning. This tutorial will show you how to use Gen.jl to build a probabilistic model of an autonomous agent that has latent beliefs and goals, and use probabilistic inference to infer the agent's goals given their observed behavior. This model is based on research at MIT ProbComp ([Cusumano-Towner et al., 2017](https://arxiv.org/abs/1704.04977)).\n",
    "\n",
    "In the images below, we see a drone that starts at the location (shown in blue), and we observe its trajectory over time (shown in orange). Our task is to predict the drone's destination. We show the inferred distribution of likely destinations (red) obtained using the probabilistic model presented in this notebook. We show inferences for the same dataset of measured drone locations, but for two different scenes. Do these inferences make sense to you?\n",
    "\n",
    "<img src=\"resources/goals/image.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes a deeper look at the model behind these inferences, introduces a data visualization methodology for probabilistic programming, and studies how the accuracy of the inferences depend on properties of the model and the amount of computation used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, edit the cell below to use the number of parallel processes you want. If you are viewing this on a server provided by ProbComp, use 32 processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addprocs(4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import Gen\n",
    "@everywhere using Gen;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modeling an autonomous agent\n",
    "\n",
    "In Gen.jl, probabilistic models are represented by probabilistic programs. Probabilistic programs are are programmatic descriptions of stochastic generative processes. A probabilistic program in Gen.jl is very much like a regular Julia function, except that certain expressions in the program are labeled with addresses using either `@g(expression, address)` or `@e(expression, address)`, and that the syntax for defining a probabilistic program is slightly different than the syntax for defining a Julia function. \n",
    "\n",
    "Below, we define an `agent_model` probabilistic program that models the beliefs, goals, and goal-directed motion of an autonomous agent. The model assumes the agent starts at a given location in a scene, and desires to move to a goal location. We model the motion of the agent by assuming that the agent walks along a path from the goal to its destination that is constructed using a path-planning algorithm based on the rapidly-exploring random tree (RRT) algorithm from robotics. We have implemented the RRT algorithm and simple library for composing scenes in Julia source files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere include(\"resources/goals/scene.jl\")\n",
    "@everywhere include(\"resources/goals/path_planner.jl\")\n",
    "@everywhere include(\"resources/goals/uniform_2d.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@program agent_model() begin\n",
    "    \n",
    "    # assumed scene\n",
    "    scene = Scene(0, 100, 0, 100) # the scene spans the square [0, 100] x [0, 100]\n",
    "    add!(scene, Tree(Point(30, 20))) # place a tree at x=30, y=20\n",
    "    add!(scene, Tree(Point(83, 80)))\n",
    "    add!(scene, Tree(Point(80, 40)))\n",
    "    \n",
    "    wall_height = 30.\n",
    "    walls = @e([\n",
    "        Wall(Point(20., 40.), 1, 40., 2., wall_height),\n",
    "        Wall(Point(60., 40.), 2, 40., 2., wall_height),\n",
    "        Wall(Point(60.-15., 80.), 1, 15. + 2., 2., wall_height),\n",
    "        Wall(Point(20., 80.), 1, 15., 2., wall_height),\n",
    "        Wall(Point(20., 40.), 2, 40., 2., wall_height) ], \"walls\")\n",
    "    for wall in walls\n",
    "        add!(scene, wall)\n",
    "    end\n",
    "    \n",
    "    # time points at which we observe the agent's location\n",
    "    observation_times = @e(collect(linspace(0.0, 200.0, 20)), \"times\")\n",
    "    \n",
    "    # assumed speed of the agent\n",
    "    speed = 1.0\n",
    "    \n",
    "    # the starting location of the agent is a random point in the scene\n",
    "    start = @g(uniform_2d(0, 100, 0, 100), \"start\")\n",
    "    \n",
    "    # the destination of the agent is a random point in the scene\n",
    "    destination = @g(uniform_2d(0, 100, 0, 100), \"destination\")\n",
    "    \n",
    "    # the path of the agent from its start location to its destination\n",
    "    # uses a simple 2D holonomic path planner based on RRT (path_planner.jl)\n",
    "    (tree, rough_path, final_path) = plan_path(start, destination, scene)\n",
    "    \n",
    "    if isnull(final_path)\n",
    "        \n",
    "        # the agent could not find a path to its destination\n",
    "        # assume it stays at the start location indefinitely\n",
    "        locations = [start for _ in observation_times]\n",
    "    else\n",
    "        \n",
    "        # the agent found a path to its destination\n",
    "        # assume it moves from the start to the destinatoin along the path at constnat speed\n",
    "        # sample its location along this path for each time in observation times\n",
    "        locations = walk_path(get(final_path), speed, observation_times)\n",
    "    end\n",
    "    \n",
    "    # assume that the observed locations are noisy measurements of the true locations\n",
    "    # assume the noise is normally distributed with standard deviation 'noise'\n",
    "    noise = 1.0\n",
    "    for (i, t) in enumerate(observation_times)\n",
    "        measured_x = @g(normal(locations[i].x, noise), \"x$i\")\n",
    "        measured_y = @g(normal(locations[i].y, noise), \"y$i\")\n",
    "    end\n",
    "    \n",
    "    # record other program state for rendering\n",
    "    @e(final_path, \"final-path\")\n",
    "    @e(scene, \"scene\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute this probabilistic program to generate probable scenarios. When we execute a probabilistic program, we record the values of any tagged expressions that were encountered during its execution (e.g. ` \"start\"`, `\"destination\"`, etc.) into a **trace**. We create a new empty trace with `ProgramTrace()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace = ProgramTrace();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We execute a probabilistic program and record its expressions into a trace with `@generate!(program(args), trace)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generate!(agent_model(), trace)\n",
    "println(\"start: \", trace[\"start\"])\n",
    "println(\"destination: \", trace[\"destination\"])\n",
    "println(\"x1 through x4: \", map((i) -> trace[\"x$i\"], 1:4))\n",
    "println(\"y1 through y4: \", map((i) -> trace[\"y$i\"], 1:4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we execute the program again it again, we get a different result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generate!(agent_model(), trace)\n",
    "println(\"start: \", trace[\"start\"])\n",
    "println(\"destination: \", trace[\"destination\"])\n",
    "println(\"x1 through x4: \", map((i) -> trace[\"x$i\"], 1:4))\n",
    "println(\"y1 through y4: \", map((i) -> trace[\"y$i\"], 1:4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the whole trace. For now, don't worry about constraints, interventions, or proposals. Note that the `recorded` section lists the values that each of the named expressions took during the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualizing the probabilistic behavior of a model using a trace rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing a trace is not a very good way to understand the probabilistic behavior of a program. Instead, we use a **trace rendering** to produce a visual representation of the trace. The trace rendering encodes the trace into a representation that the human visual system can quickly interpret. In Gen.jl a trace renderer is simply object that has a method \"`render(renderer, trace::Trace)`\". In Jupyter notebooks, we render traces using JavaScript code that renders traces onto a Document Object Model (DOM) element in the output of notebook cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the file included below, we define a trace renderer for `agent_model` using JavaScript and CSS. In particular we use the Javascript data visualization library [D3](https://d3js.org/). This cell returns CSS and Javascript code into its output cell, which gets added to the DOM by Jupyter. Inside this file, we define the trace renderer in Javascript, and register it with Gen using the Javascript function `Gen.register_jupyter_renderer`. Each Javascript trace renderer is given a name when it is registered, so that the Julia code can send the trace data to the right renderer. A Javascript trace renderer is a function with signature `function(dom_id, trace, configuration) {.. }`. The first argument `dom_id` defines what element of the DOM the renderer should write to, and `trace` contains the trace data sent from Julia. The Javascript code in the cell below should have correct Javascript syntax highlighting (you may have to click in the cell to activate the syntax highlighting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"resources/goals/rendering.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a DOM element that the trace renderer renders to using the `Figure` function in Julia. The `here(figure)` places a DOM element in the output of the cell onto which Javascript trace renderers will be able to render traces. It should appear as as a mostly empty output area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure = Figure(num_cols=2, width=900, height=400, trace_width=100, trace_height=100, margin_top=20,\n",
    "                titles=[\"Trace\"])\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we construct a Julia trace renderer object that will delegate rendering to the Javascript trace renderer that we defined above. We attach the renderer to the first viewport in the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict())\n",
    "attach(renderer, id(figure => 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then execute the program, and render the resulting trace. You should see the trace rendering appear on the left side of the rendering area above. Run the cell below a few times to see different executions of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@generate!(agent_model(), trace)\n",
    "render(renderer, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wrote a renderer that just shows the legend. We ask that renderer to put a legend in the right side of the rendering area above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "legend_renderer = JupyterInlineRenderer(\"agent_model_legend_renderer\", Dict())\n",
    "attach(legend_renderer, id(figure => 2))\n",
    "render(legend_renderer, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probabilistic program is stochastic, and the distribution over its executions defines a probability distribution over potential scenarios. Let's get a sense of this probability distribution by rendering many executions, one after another, in an animation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure = Figure(num_cols=2, width=900, height=400, trace_width=100, trace_height=100, margin_top=20,\n",
    "                titles=[\"Trace\"])\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attach(legend_renderer, id(figure => 2))\n",
    "render(legend_renderer, trace)\n",
    "attach(renderer, id(figure => 1))\n",
    "for i=1:100\n",
    "    trace = ProgramTrace()\n",
    "    @generate!(agent_model(), trace)\n",
    "    render(renderer, trace)\n",
    "    sleep(0.1)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also render many runs side by side in a grid, instead of an animation. This also gives a sense of the probability distribution represented by the probabilistic program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i=1:12\n",
    "    trace = ProgramTrace()\n",
    "    @generate!(agent_model(), trace)\n",
    "    attach(renderer, id(figure => i))\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key feature of Gen.jl is the ability to constrain the values of random choices that a probabilistic program makes during the course of its execution. Let's see how we can modify the behavior of the program if we constrain the starting location of the agent and its destination location using the `constrain!(trace, name, value)` method. We will constrain the start location to lie in the upper left corner and the destination to lie in the bottom right corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i=1:12\n",
    "    trace = ProgramTrace()\n",
    "    constrain!(trace, \"start\", Point(10, 10))\n",
    "    constrain!(trace, \"destination\", Point(90, 90))\n",
    "    @generate!(agent_model(), trace)\n",
    "    attach(renderer, id(figure => i))\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a sense of the variability in the paths that the agent takes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get a sense for the variability by overlaying many traces on top of one another. Our renderer supports this as part of its configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_cols=2, width=900, height=400, trace_width=100, trace_height=100, margin_top=20,\n",
    "                titles=[\"Trace\"])\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attach(legend_renderer, id(figure => 2))\n",
    "render(legend_renderer, trace)\n",
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"path\" => \"overlay\"))\n",
    "attach(renderer, id(figure => 1))\n",
    "CSS(\"#$(id(figure)) .path { visibility: hidden; }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i=1:20\n",
    "    trace = ProgramTrace()\n",
    "    intervene!(trace, \"start\", Point(10, 10))\n",
    "    intervene!(trace, \"destination\", Point(90, 90))\n",
    "    @generate!(agent_model(), trace)\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Probabilistic inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have generated scenarios that the model thinks are probable, and we have constrained some random choices and simulated the consequence. However, suppose we had observed the start location of the agent, and a certain sequence of locations of the agent along its path, and we wanted to know probable goal locations?\n",
    "\n",
    "This is a query that cannot be answered simply by forward simulation of the program, because the location of the agent is a *consequence* and not a *cause* of the destination. We can easily find probable consequences given the causes as we did above, but finding probable causes given the consequences requires a bit more work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example dataset showing measured locations for the first 7 time points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    Point(10.3867,10.3889)\n",
    "    Point(11.0188,20.0843)\n",
    "    Point(11.6663,30.0142)\n",
    "    Point(11.4507,41.5159)\n",
    "    Point(13.8081,53.0258)\n",
    "    Point(13.1958,61.3572)\n",
    "    Point(17.1566,73.7131)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in inference is to constrain the random choices that are observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace = ProgramTrace()\n",
    "constrain!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we run the program in this trace, we find that the score of the trace tells us how well the other values in the trace match the value of the constraints. Very negative scores that the other values in the trace, such as the destination and the projected path, do not match well with the constrained path points. The path points that were constrained are identified in the trace renderings by a dashed border."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=3, num_cols=3, width=900, height=900, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSS(\"\"\"\n",
    "    #$(id(figure)) .path.recorded { visibility: hidden; }\n",
    "    #$(id(figure)) .score { visibility: visible; }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict())\n",
    "for i=1:30\n",
    "    t = deepcopy(trace)\n",
    "    (score, _) = @generate!(agent_model(), t)\n",
    "    attach(renderer, id(figure => i))\n",
    "    render(renderer, t; score=score)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a large number of traces generated by the program, and a score for each trace that tells us how well that trace matches the constraints, we can select those trace that match the constraints. These traces then represent plausible hypotheses that can explain the observed data. This is the approach taken by the two basic inference algorithms that we implement next, *Importance Sampling* and *Metropolis-Hastings*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below shows a basic importance sampling procedure that uses the score of traces to probabilistically filter them and tries to select a trace that explains the data well. Note that this procedure is a regular Julia function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function agent_model_importance_sampling(trace::ProgramTrace, num_samples::Int)\n",
    "    \n",
    "    # the 'trace' argument contains the constraints that represent the \n",
    "    # observed dataset. \n",
    "    \n",
    "    # perform many independent executions of the probabilistic program, and \n",
    "    # record each execution in a trace. store the 'score' for each trace, \n",
    "    # which encodes how well the trace matches the constraints\n",
    "    traces = Vector{ProgramTrace}(num_samples)\n",
    "    scores = Vector{Float64}(num_samples)\n",
    "    for k=1:num_samples\n",
    "        t = deepcopy(trace)\n",
    "        (scores[k], _) = @generate!(agent_model(), t)\n",
    "        traces[k] = t\n",
    "    end\n",
    "    \n",
    "    # compute a reltaive weight for each trace indicating how well the trace\n",
    "    # matches the constraints relative to the other traces generated. A large\n",
    "    # weight indicates that the trace matches the constraints well, and may be\n",
    "    # a better explanation for the observed data than other trace.\n",
    "    \n",
    "    # weights = exp.(scores) / sum(exp.(scores))\n",
    "    weights = exp.(scores - logsumexp(scores))\n",
    "    weights = weights / sum(weights)\n",
    "    \n",
    "    # pick a trace in propotion to its relative weight and return it\n",
    "    chosen = rand(Categorical(weights))\n",
    "    return traces[chosen]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this Julia function treats the execution traces of the probabilistic program `agent_model` as data, this inference procedure is an example of a [meta-program](https://en.wikipedia.org/wiki/Metaprogramming). In Gen.jl, inference is done using meta-programs that reason about the traces of other programs. This is in contrast to most other probabilistic programming systems, in which users do not write their own custom meta-programs, but instead rely on built-in generic inference techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the output of our importance sampling procedure. Recall that each run of the procedure produces one trace of the `agent_model` probabilistic program. Note that the importance sampling procedure is stochastic---repeated executions will generate different traces. This is an important feature---we want inference algorithms to give us probable explanations for the data, but also a sense of how uncertain we are in those explanations. By executing the inference algorithm many times, we can get a sense of the uncertainty in the inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_samples_list = [1, 4, 16]\n",
    "figure = Figure(num_rows=1, num_cols=length(num_samples_list),\n",
    "                width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=map((n) -> \"SIR ($n samples)\", num_samples_list))\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSS(\"\"\"\n",
    "    #$(id(figure)) .path.recorded { visibility: hidden; }\n",
    "    #$(id(figure)) .path.constrained { visibility: visible; }\n",
    "    #$(id(figure)) .path_segments { visibility: hidden; }\n",
    "    #$(id(figure)) .destination { fill-opacity: 0.5; }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"destination\" => \"overlay\"))\n",
    "\n",
    "trace = ProgramTrace()\n",
    "intervene!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end\n",
    "for (i, num_samples) in enumerate(num_samples_list)\n",
    "    attach(renderer, id(figure => i))\n",
    "    title =  \"SIR ($num_samples particles)\"\n",
    "    for j=1:100\n",
    "        output_trace = agent_model_importance_sampling(trace, num_samples)\n",
    "        render(renderer, output_trace)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the inference algorithm using `num_samples=1`, `num_samples=4`, and `num_samples=16`. Note that when we increase `num_samples` we get more plausible traces as output. For `num_samples=16`, the algorithm tells us that it thinks the agent is headed either into the box or in the bottom left or bottom of the scene. Also note that the more plausible answers come at a greater computation cost---we have to wait longer for each new sample to arrive. Understanding the time-accuracy tradeoffs in approximate probabilistic inference algorithms is an active area of research (see [Cusumano-Towner, Mansinghka 2016](https://arxiv.org/abs/1705.07224) for recent work in this area)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we show a basic Metropolis-Hastings inference allgorithm written in Gen.jl that operates according to similar principles. Instead of generating a bunch of traces and then scoring each and selecting it as output, Metropolis-Hastings generates traces one by one and decides to stochastically replace the previous trace with a new trace if the new trace has a higher score than the previous trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict())\n",
    "figure = Figure(num_rows=1, num_cols=3, width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=[\"proposed trace\", \"current trace\"])\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSS(\"\"\"\n",
    "    #$(id(figure)) .path.recorded { visibility: hidden; }\n",
    "    #$(id(figure)) .score { visibility: visible; }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attach(legend_renderer, id(figure => 3))\n",
    "render(legend_renderer, trace)\n",
    "current_trace = ProgramTrace()\n",
    "intervene!(current_trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(dataset)\n",
    "    constrain!(current_trace, \"x$i\", point.x)\n",
    "    constrain!(current_trace, \"y$i\", point.y)\n",
    "end\n",
    "(current_score, _) = @generate!(agent_model(), current_trace)\n",
    "for i=1:100\n",
    "    proposed_trace = deepcopy(current_trace)\n",
    "    (proposed_score, _) = @generate!(agent_model(), proposed_trace)\n",
    "    if log(rand()) < proposed_score - current_score\n",
    "        current_trace = proposed_trace\n",
    "        current_score = proposed_score\n",
    "    end\n",
    "    attach(renderer, id(figure => 1))\n",
    "    render(renderer, proposed_trace, score=proposed_score)\n",
    "    attach(renderer, id(figure => 2))\n",
    "    render(renderer, current_trace, score=current_score)\n",
    "    sleep(0.1)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we change the scene in the model by adding a door in the top wall. We do this by intervening on the \"walls\" variable in the `agent_model` probabilistic program. We use the same dataset, and compare the inferences when the model assumes the original scene (without the door) and the modified scene (with the door). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=1, num_cols=2, width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=[\"without door\", \"with door\"])\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSS(\"\"\"\n",
    "    #$(id(figure)) .path.recorded { visibility: hidden; }\n",
    "    #$(id(figure)) .path.constrained { visibility: visible; }\n",
    "    #$(id(figure)) .path_segments { visibility: hidden; }\n",
    "    #$(id(figure)) .destination { fill-opacity: 0.5; }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"destination\" => \"overlay\"))\n",
    "num_samples = 64\n",
    "num_approximate_samples = 50\n",
    "trace = ProgramTrace()\n",
    "intervene!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end\n",
    "\n",
    "# scene without door\n",
    "attach(renderer, id(figure => 1))\n",
    "for j=1:num_approximate_samples\n",
    "    output_trace = agent_model_importance_sampling(trace, num_samples)\n",
    "    render(renderer, output_trace)\n",
    "end\n",
    "\n",
    "# scene with door\n",
    "wall_height = 30.\n",
    "new_walls = [\n",
    "    Wall(Point(60.-15., 40.), 1, 15. + 2., 2., wall_height),\n",
    "    Wall(Point(20., 40.), 1, 15., 2., wall_height),\n",
    "    Wall(Point(60., 40.), 2, 40., 2., wall_height),\n",
    "    Wall(Point(60.-15., 80.), 1, 15. + 2., 2., wall_height),\n",
    "    Wall(Point(20., 80.), 1, 15., 2., wall_height),\n",
    "    Wall(Point(20., 40.), 2, 40., 2., wall_height) \n",
    "]\n",
    "intervene!(trace, \"walls\", new_walls)\n",
    "attach(renderer, id(figure => 2))\n",
    "for j=1:num_approximate_samples\n",
    "    output_trace = agent_model_importance_sampling(trace, num_samples)\n",
    "    render(renderer, output_trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is no upper door, inference tells us that it is probable that the agent is headed into the room. When there is an upper door, inference tells us it is unlikely that the agent is headed into the room. Intuitively, this is because the model assumes that the agent takes relatively direct paths from its start location to its destination. If the agent were headed into the room, it would have taken the more direct route through the top door."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Improving the model\n",
    "\n",
    "The probabilistic model `agent_model` used above made a lot of assumptions that are unlikely to hold in the real world. For example, the agent always takes pretty direct paths from its starting location to its final destination. What if the agent is more unpredictable? What if it takes detours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a dataset that has a detour in it, and that does not match our model's expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detour_dataset = [\n",
    "    Point(9.59825,8.92063)\n",
    "    Point(21.8936,9.54817)\n",
    "    Point(30.9534,10.8819)\n",
    "    Point(43.1137,9.75395)\n",
    "    Point(48.8929,10.4189)\n",
    "    Point(46.0282,21.7662)\n",
    "    Point(35.0281,25.9994)\n",
    "    Point(27.2084,33.5729)\n",
    "    Point(20.1662,39.9398)\n",
    "    Point(18.7309,50.0026)\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_cols=2, width=900, height=400, trace_width=100, trace_height=100, margin_top=20)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSS(\"\"\"\n",
    "    #$(id(figure)) .path.recorded { visibility: hidden; }\n",
    "    #$(id(figure)) .path.constrained { visibility: visible; }\n",
    "    #$(id(figure)) .path_segments { visibility: hidden; }\n",
    "    #$(id(figure)) .destination { visibility: hidden; }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"destination\" => \"overlay\"))\n",
    "attach(renderer, id(figure => 1))\n",
    "\n",
    "# show the dataset above.\n",
    "trace = ProgramTrace()\n",
    "intervene!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(detour_dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end\n",
    "@generate!(agent_model(), trace)\n",
    "\n",
    "render(renderer, trace)\n",
    "\n",
    "# show a legend\n",
    "attach(legend_renderer, id(figure => 2))\n",
    "render(legend_renderer, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we try to do probabilistic inference given this dataset, using the `agent_model` model. We will use the same importance sampling algorithm we wrote above, with the same settings for the  `num_samples` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_samples_list = [1, 4, 16]\n",
    "figure = Figure(num_rows=1, num_cols=length(num_samples_list),\n",
    "                width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=map((n) -> \"SIR ($n samples)\", num_samples_list))\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSS(\"\"\"\n",
    "    #$(id(figure)) .path.recorded { visibility: hidden; }\n",
    "    #$(id(figure)) .path.constrained { visibility: visible; }\n",
    "    #$(id(figure)) .path_segments { visibility: hidden; }\n",
    "    #$(id(figure)) .destination { fill-opacity: 0.5; }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace = ProgramTrace()\n",
    "intervene!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(detour_dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end\n",
    "\n",
    "num_approximate_samples = 50\n",
    "for (i, num_samples) in enumerate(num_samples_list)\n",
    "    attach(renderer, id(figure => i))\n",
    "    for j=1:num_approximate_samples\n",
    "        output_trace = agent_model_importance_sampling(trace, num_samples)\n",
    "        render(renderer, output_trace)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inferences do not look intuitive. This is because the model `agent_model` cannot explain the detour. It assumes that the detour must be the goal, an it explains the observed data as a very unlikely accident of noise. This is an example of **model mis-specification**.  In order to make reasonable inferences for datasets that may contain a detour, we need to improve our model. Here is a new probabilistic program that models an agent that may or may not use an arbitrary waypoint (e.g. detour) when planning its path from its starting location to its destination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere @program agent_waypoint_model() begin\n",
    "    \n",
    "    # assumed scene\n",
    "    scene = Scene(0, 100, 0, 100) # the scene spans the square [0, 100] x [0, 100]\n",
    "    add!(scene, Tree(Point(30, 20))) # place a tree at x=30, y=20\n",
    "    add!(scene, Tree(Point(83, 80)))\n",
    "    add!(scene, Tree(Point(80, 40)))\n",
    "    \n",
    "    wall_height = 30.\n",
    "    walls = @e([\n",
    "        Wall(Point(20., 40.), 1, 40., 2., wall_height)\n",
    "        Wall(Point(60., 40.), 2, 40., 2., wall_height)\n",
    "        Wall(Point(60.-15., 80.), 1, 15. + 2., 2., wall_height)\n",
    "        Wall(Point(20., 80.), 1, 15., 2., wall_height)\n",
    "        Wall(Point(20., 40.), 2, 40., 2., wall_height) ], \"walls\")\n",
    "    for wall in walls\n",
    "        add!(scene, wall)\n",
    "    end\n",
    "    \n",
    "    # time points at which we observe the agent's location\n",
    "    observation_times = @e(collect(linspace(0.0, 200.0, 20)), \"times\")\n",
    "    \n",
    "    # assumed speed of the agent\n",
    "    speed = 1.0\n",
    "    \n",
    "    # the starting location of the agent is a random point in the scene\n",
    "    start = @g(uniform_2d(0, 100, 0, 100), \"start\")\n",
    "    \n",
    "    # the destination of the agent is a random point in the scene\n",
    "    destination = @g(uniform_2d(0, 100, 0, 100), \"destination\")\n",
    "    \n",
    "    if @g(flip(0.5), \"use-waypoint\")\n",
    "        waypoint = @g(uniform_2d(0, 100, 0, 100), \"waypoint\")\n",
    "        (tree1, rough_path1, final_path1) = plan_path(start, waypoint, scene)\n",
    "        (tree2, rough_path2, final_path2) = plan_path(waypoint, destination, scene)\n",
    "        \n",
    "        # if either path planner sub-problem failed, then no path was found (final_path is null)\n",
    "        if isnull(final_path1) || isnull(final_path2)\n",
    "            final_path = Nullable{Path}() # null\n",
    "        else\n",
    "            final_path = Nullable{Path}(concatenate(get(final_path1), get(final_path2)))\n",
    "        end\n",
    "    else\n",
    "        (tree, rough_path, final_path) = plan_path(start, destination, scene)\n",
    "    end\n",
    "    \n",
    "    # the path of the agent from its start location to its destination\n",
    "    # uses a simple 2D holonomic path planner based on RRT (path_planner.jl)\n",
    "    \n",
    "    if @e(isnull(final_path), \"planning-failed\")\n",
    "        \n",
    "        # the agent could not find a path to its destination\n",
    "        # assume it stays at the start location indefinitely\n",
    "        locations = [start for _ in observation_times]\n",
    "    else\n",
    "        \n",
    "        # the agent found a path to its destination\n",
    "        # assume it moves from the start to the destinatoin along the path at constnat speed\n",
    "        # sample its location along this path for each time in observation times\n",
    "        locations = walk_path(get(final_path), speed, observation_times)\n",
    "    end\n",
    "    \n",
    "    # assume that the observed locations are noisy measurements of the true locations\n",
    "    # assume the noise is normally distributed with standard deviation 'noise'\n",
    "    noise = 1.0\n",
    "    for (i, t) in enumerate(observation_times)\n",
    "        measured_x = @g(normal(locations[i].x, noise), \"x$i\")\n",
    "        measured_y = @g(normal(locations[i].y, noise), \"y$i\")\n",
    "    end\n",
    "    \n",
    "    # record other program state for rendering\n",
    "    @e(final_path, \"final-path\")\n",
    "    @e(scene, \"scene\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some simulations from the program, for a constrained start and destination that both lie one side of the scene. The waypoint, when there is one, is shown as a pink circle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=3, num_cols=3, width=900, height=900, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict())\n",
    "traces = []\n",
    "for i=1:18\n",
    "    trace = ProgramTrace()\n",
    "    constrain!(trace, \"start\", Point(10, 10))\n",
    "    constrain!(trace, \"destination\", Point(30, 90))\n",
    "    @generate!(agent_waypoint_model(), trace)\n",
    "    attach(renderer, id(figure => i))\n",
    "    render(renderer, trace)\n",
    "    push!(traces, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that sometimes, the path has a clear waypoint/detour whereas other times it does not. Run the above cell a few times if you don't initially see a clear waypoint. The current trace rendering does not show the waypoint explicitly, but it could be extended to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do inference in this new model on the detour dataset. We'll use importance sampling again. The only change in this procedure from the earlier importance sampling procedure is the choice of model (`agent_waypoint_model` instead of `agent_model`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere function agent_waypoint_model_importance_sampling(trace::ProgramTrace, num_samples::Int)\n",
    "    traces = Vector{ProgramTrace}(num_samples)\n",
    "    scores = Vector{Float64}(num_samples)\n",
    "    for k=1:num_samples\n",
    "        t = deepcopy(trace)\n",
    "        (scores[k], _) = @generate!(agent_waypoint_model(), t)\n",
    "        traces[k] = t\n",
    "    end\n",
    "    weights = exp.(scores - logsumexp(scores))\n",
    "    weights = weights / sum(weights)\n",
    "    chosen = rand(Categorical(weights))\n",
    "    return traces[chosen]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_list = [1, 4, 16]\n",
    "figure = Figure(num_rows=1, num_cols=length(num_samples_list),\n",
    "                width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=map((n) -> \"SIR ($n samples)\", num_samples_list))\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSS(\"\"\"\n",
    "    #$(id(figure)) .path.recorded { visibility: hidden; }\n",
    "    #$(id(figure)) .path.constrained { visibility: visible; }\n",
    "    #$(id(figure)) .path_segments { visibility: hidden; }\n",
    "    #$(id(figure)) .destination { fill-opacity: 0.5; }\n",
    "    #$(id(figure)) .waypoint { visibility: hidden; }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace = ProgramTrace()\n",
    "constrain!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(detour_dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end\n",
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"destination\" => \"overlay\"))\n",
    "num_approximate_samples = 50\n",
    "for (i, num_samples) in enumerate(num_samples_list)\n",
    "    attach(renderer, id(figure => i))\n",
    "    for j=1:num_approximate_samples\n",
    "        output_trace = agent_waypoint_model_importance_sampling(trace, num_samples)\n",
    "        render(renderer, output_trace)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the results are not accurate. Let's try more computation. We will try many more particles, and we will parallelize across the 32 cores on this instance, but it will still take a minute or two to run. Note that since we are parallelizing with `pmap`, the samples will appear all at once and not incrementally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please the number of samples below to be `[64, 256, 1024]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples_list = [64];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=1, num_cols=length(num_samples_list),\n",
    "                width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=map((n)-> \"SIR ($n samples)\", num_samples_list))\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSS(\"\"\"\n",
    "    #$(id(figure)) .path.recorded { visibility: hidden; }\n",
    "    #$(id(figure)) .path.constrained { visibility: visible; }\n",
    "    #$(id(figure)) .path_segments { visibility: hidden; }\n",
    "    #$(id(figure)) .destination { fill-opacity: 0.5; }\n",
    "    #$(id(figure)) .waypoint { visibility: hidden; }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_approximate_samples = 50\n",
    "for (i, num_samples) in enumerate(num_samples_list)\n",
    "    attach(renderer, id(figure => i))\n",
    "    \n",
    "    # parallel map\n",
    "    output_traces = pmap(agent_waypoint_model_importance_sampling,\n",
    "                          [trace for _ in 1:num_approximate_samples],\n",
    "                          [num_samples for _ in 1:num_approximate_samples])\n",
    "    for output_trace in output_traces\n",
    "        render(renderer, output_trace)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extra computation seems to have given us reasonable inferences. Recall that inference in the original model with a typical dataset only required 16 particles to give reasonalbe results for a particular dataset. Why do we need to do more computation to get accurate inferences for `agent_waypoint_path` than we needed for `agent_model`? This is because a random execution of the improved model is a lot less likely to match a typical dataset generated from it than a random execution of the original model was to match a typical dataset generated from it. Conceptually, the distribution on datasets produced by `agent_waypoint_path` has more entropy than the distribution on datasets produced by `agent_path`. This means we need to increase the number of samples to incrase the probability that we get one that matches the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
